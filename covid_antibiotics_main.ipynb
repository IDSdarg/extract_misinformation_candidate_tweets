{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, scipy, json, re, time, pickle\n",
    "import pandas as pd\n",
    "import workers\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import feather, pytz, spacy, datetime\n",
    "from itertools import chain\n",
    "from datetime import timezone\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sbert = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16396, 4)\n"
     ]
    }
   ],
   "source": [
    "def extract_tweet_info(x):\n",
    "    return [x['id'], int(x['created_at']/1000), x.get('user_id', ''), x['tweet']]\n",
    "\n",
    "file_list = glob.glob('../dat/hks_misinformation_review/covid_antibiotics_replies/*.json')\n",
    "\n",
    "sampled_tweets = []\n",
    "for file in file_list:\n",
    "    for line in open(file, 'r', encoding='utf-8'):\n",
    "        sampled_tweets.append(extract_tweet_info(json.loads(line)))\n",
    "        \n",
    "sampled_tweets_df = pd.DataFrame(sampled_tweets, columns=['id', 'created', 'uid', 'text'])\n",
    "print(sampled_tweets_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of df in the year 2020: (16383, 4)\n",
      "size of df after dropping duplicates: (16383, 4)\n"
     ]
    }
   ],
   "source": [
    "covid_df = sampled_tweets_df.copy()\n",
    "covid_df.index = covid_df.created.apply(lambda x: datetime.datetime.fromtimestamp(x, pytz.utc))\n",
    "covid_df = covid_df.sort_index()\n",
    "\n",
    "criteria  = (covid_df.index.year==2020)\n",
    "covid_df = covid_df[criteria]\n",
    "print(\"size of df in the year 2020:\", covid_df.shape)\n",
    "\n",
    "covid_df = covid_df.drop_duplicates()\n",
    "print(\"size of df after dropping duplicates:\", covid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
